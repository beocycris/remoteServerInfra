# Brewery Infrastructure

## üìã Deployment-Anleitung

### Szenario 1: Single-Node (einfaches Deployment)

F√ºr einen einzelnen Host (z.B. lokale VM oder einzelner Server):

```bash
# Repo klonen und SSH-Variablen setzen
git clone <repo-url>
cd remoteServerInfra

export TARGET_USER="ubuntu"
export TARGET_HOST="10.10.100.162"
export TARGET_DIR="/home/ubuntu/brewery-infra"

# Core-Infrastruktur installieren
./deploy_infra.sh --core-only

# Monitoring deployen (optional)
./deploy_infra.sh --monitoring
```

**Resultat:** Docker + Portainer + optional Prometheus/Grafana/InfluxDB auf einem Host.

---

### Szenario 2: Multi-Node Swarm (Monitoring √ºber mehrere Plattformen)

F√ºr verteilte Infrastruktur mit automatischer Metrik-Aggregation √ºber alle Nodes:

#### **Schritt 1: Manager-Node vorbereiten und Swarm initialisieren**

```bash
# Auf deiner lokalen Maschine (Workstation/Mac)
export TARGET_USER="ubuntu"
export TARGET_HOST="192.168.1.10"      # Manager-IP
export TARGET_DIR="/home/ubuntu/brewery-infra"

# Core installieren + Swarm initialisieren
./deploy_infra.sh --core-only

# Dann Monitoring + Swarm Init
./deploy_infra.sh --monitoring \
  --swarm-init \
  --swarm-advertise-addr=192.168.1.10
```

Das Script initialisiert den Swarm. Der Manager ist jetzt ready zum Empfang von Workers und zus√§tzlichen Managern.

#### **Schritt 2: Worker-Nodes (z.B. Raspberry Pi, zweiter Server) beitreten**

Pro Worker-Host **von deiner lokalen Maschine aus** starten:

```bash
# SSH-Variablen f√ºr Worker #1 setzen
export TARGET_USER="ubuntu"
export TARGET_HOST="192.168.1.11"      # Worker-IP 
export TARGET_DIR="/home/ubuntu/brewery-infra"

# 1. Basis-Installation auf Worker
./deploy_infra.sh --core-only

# 2. Monitoring starten + zum Swarm beitreten
# Der Token wird AUTOMATISCH vom Manager abgerufen!
./deploy_infra.sh --monitoring \
  --swarm-join-worker \
  --swarm-manager-addr=192.168.1.10:2377
```

**F√ºr weitere Worker (Worker #2, #3, ...):**

```bash
export TARGET_HOST="192.168.1.12"      # IP des n√§chsten Workers √§ndern

./deploy_infra.sh --core-only

./deploy_infra.sh --monitoring \
  --swarm-join-worker \
  --swarm-manager-addr=192.168.1.10:2377
  # Token wird wieder automatisch abgerufen!
```

> **Wichtig:** Die `export TARGET_*` Variablen **m√ºssen vor jedem Deployment gesetzt werden**, damit SSH auf den richtigen Host verbindet!
> 
> **Token-Abruf:** Das Script holt den aktuellen Worker-Token automatisch vom Manager ab ‚Äì du brauchst `--swarm-join-token` nicht anzugeben!

#### **Schritt 3: Swarm-Cluster pr√ºfen**

SSH in den Manager und pr√ºfe den Swarm-Status:

```bash
ssh ubuntu@192.168.1.10

# Swarm-√úbersicht
docker node ls

# Stack-ServiceStatus
docker service ls
docker stack services brewery-monitoring
```

**Erwartetes Resultat:**
```
ID             HOSTNAME          STATUS    AVAILABILITY  MANAGER STATUS
abcd1234...    manager           Ready     Active        Leader
efgh5678...    worker1           Ready     Active        
ijkl9012...    worker2           Ready     Active        
```

Services werden verteilt:
- `prometheus`, `grafana`, `influxdb` ‚Üí nur auf Manager
- `node-exporter`, `cadvisor`, `glances` ‚Üí auf **jedem Node** (global)
- `telegraf` ‚Üí 2 Replikas √ºber Worker verteilt

---

### Szenario 3: Manager-Redundancy (HA-Setup)

F√ºr h√∂here Verf√ºgbarkeit mit mehreren Managern:

```bash
# SSH-Variablen f√ºr zus√§tzlichen Manager setzen
export TARGET_USER="ubuntu"
export TARGET_HOST="192.168.1.13"      # IP des neuen Managers
export TARGET_DIR="/home/ubuntu/brewery-infra"

./deploy_infra.sh --core-only

./deploy_infra.sh --monitoring \
  --swarm-join-manager \
  --swarm-manager-addr=192.168.1.10:2377
```

F√ºr HA-Setup mindestens **3 Manager-Nodes** empfohlen (Quorum-Mehrheit).

> Der Token wird automatisch vom existierenden Manager abgerufen!

---

### Szenario 4: Hotspot + Swarm (AP-Modus + Monitoring)

Falls ein Node als WLAN-Access-Point + Swarm-Worker laufen soll:

```bash
# SSH-Variablen f√ºr Hotspot-Node
export TARGET_USER="ubuntu"
export TARGET_HOST="192.168.1.14"      # Hotspot-Node IP
export TARGET_DIR="/home/ubuntu/brewery-infra"

# 1. Core installieren
./deploy_infra.sh --core-only

# 2. Hotspot initialisieren
./deploy_infra.sh --hotspot

# 3. Monitoring + Swarm-Join
./deploy_infra.sh --monitoring \
  --swarm-join-worker \
  --swarm-manager-addr=192.168.1.10:2377
```

---

## ÔøΩ Swarm Join-Token Verwaltung

### **Automatischer Token-Abruf (mit Fallback)**

Das Deploy-Script versucht den Token zuerst **automatisch** vom Manager abzurufen. Falls das fehlschl√§gt, wird Fallback auf manuelle Methode:

```bash
export TARGET_USER="ubuntu"
export TARGET_HOST="192.168.1.11"           # Worker-IP
export TARGET_DIR="/home/ubuntu/brewery-infra"

./deploy_infra.sh --monitoring \
  --swarm-join-worker \
  --swarm-manager-addr=192.168.1.10:2377
```

**Normal-Fall (Auto erfolgreich):**
- Script versucht: `ssh ubuntu@192.168.1.10 "docker swarm join-token worker -q"`
- Token wird automatisch verwendet ‚úÖ

**Fallback-Fall (Auto fehlgeschlagen, z.B. SSH-Probleme):**
```
üü® Token-Abruf fehlgeschlagen ‚Äì Fallback auf manuelle Methode
üü® Bitte Token manuell abrufen und √ºbergeben:
üü®
üü®   ssh ubuntu@192.168.1.10 "docker swarm join-token worker -q"
üü®
üü® Dann Deploy mit Token wiederholen:
üü®   ./deploy_infra.sh --monitoring \
üü®     --swarm-join-worker \
üü®     --swarm-manager-addr=192.168.1.10:2377 \
üü®     --swarm-join-token=<TOKEN>
```

### **Manueller Token-Abruf (wenn n√∂tig)**

Falls du den Token selbst ben√∂tigst oder als Fallback nutzen willst:

```bash
# SSH zum Manager
ssh ubuntu@192.168.1.10

# Worker-Join-Befehl inkl. Token anzeigen
docker swarm join-token worker

# Nur den Token selbst (ohne Befehl)
docker swarm join-token worker -q

# Manager-Token f√ºr HA-Setup
docker swarm join-token manager -q
```

**Beispiel-Output:**
```
SWMTKN-1-3pu6hszjas19xyp7ghgosixsyx97ocja8nj5gvbghosixsyx97ocja8nj5g
```

### **Fallback: Token manuell √ºbergeben**

Falls der auto-Abruf nicht funktioniert, kannst du den Token auch manuell √ºbergeben:

```bash
export TARGET_HOST="192.168.1.11"
export TOKEN=$(ssh ubuntu@192.168.1.10 "docker swarm join-token worker -q")

./deploy_infra.sh --monitoring \
  --swarm-join-worker \
  --swarm-manager-addr=192.168.1.10:2377 \
  --swarm-join-token="$TOKEN"
```

---

### **Grafana √∂ffnen**
- URL: `http://<MANAGER_IP>:3000`
- Benutzer: `admin` / Passwort: `BenFra2020!!`
- Dashboards werden automatisch provisioniert

### **Prometheus Queries**
- URL: `http://<MANAGER_IP>:9090`
- Queries auf alle Worker-Nodes verteilt (z.B. `node_cpu_seconds_total{instance=~".*:9100$"}`)

### **InfluxDB**
- URL: `http://<MANAGER_IP>:8086`
- Benutzer: `admin` / Token: `BenFra2020!!`
- Bucket: `brewery` (MQTT-Daten)

### **Services im Swarm verwalten**

```bash
# Im Manager-Node SSH-Session (oder ssh ubuntu@<MANAGER_IP> davor)

# Stack neu deployen (z.B. nach Config-√Ñnderung)
cd brewery-infra/monitoring
docker stack deploy -c docker-stack.yml brewery-monitoring

# Service skalieren
docker service scale brewery-monitoring_telegraf=3

# Service-Logs
docker service logs brewery-monitoring_telegraf

# Node Labels zum Scheduling setzen
docker node update --label-add region=zone-a worker1
docker node update --label-add region=zone-b worker2

# Anschlie√üend docker-stack.yml anpassen f√ºr Placement-Constraints
```

---

## ‚úÖ Deployment-Checklist

- [ ] SSH-Zugriff auf alle Hosts testet
- [ ] `TARGET_USER` und `TARGET_HOST` korrekt gesetzt
- [ ] Docker CE ist auf allen Nodes installierbar
- [ ] Netzwerk: alle Nodes k√∂nnen einander auf Port 2377 (Swarm) erreichen
- [ ] Manager: mindestens Port 2377, 7946 (TCP+UDP), 4789 (UDP) offen
- [ ] Worker: Port 7946, 4789 f√ºr Overlay-Netzwerk
- [ ] SSH-Keys f√ºr passwordless Login (optional, aber empfohlen)
- [ ] Backup: `./postinstall` Verzeichnis vor √Ñnderungen sichern

---

## üîß Troubleshooting & H√§ufige Probleme

### **Problem: SSH-Timeout**
```bash
# SSH manuell testen
ssh -v ubuntu@192.168.1.10
# Falls erforderlich, SSH-Key konfigurieren
ssh-copy-id -i ~/.ssh/id_rsa.pub ubuntu@192.168.1.10
```

### **Problem: Token-Abruf vom Manager fehlgeschlagen**
```bash
# 1. Pr√ºfe, ob Manager erreichbar ist
ping 192.168.1.10

# 2. Pr√ºfe SSH-Zugriff zum Manager
ssh ubuntu@192.168.1.10 "docker node ls"

# 3. Pr√ºfe, ob Manager im Swarm aktiv ist
ssh ubuntu@192.168.1.10 "docker info | grep 'Swarm: active'"

# 4. Token manuell anzeigen
ssh ubuntu@192.168.1.10 "docker swarm join-token worker -q"

# 5. Falls auto-Abruf immer noch fehlschl√§gt ‚Üí Token manuel √ºbergeben
TOKEN=$(ssh ubuntu@192.168.1.10 "docker swarm join-token worker -q")
./deploy_infra.sh --monitoring \
  --swarm-join-worker \
  --swarm-manager-addr=192.168.1.10:2377 \
  --swarm-join-token="$TOKEN"
```

### **Problem: Worker-Node tritt Swarm nicht bei**
```bash
# Auf dem Worker pr√ºfen
ssh ubuntu@192.168.1.11
docker swarm leave --force
# Token erneut abrufen vom Manager
ssh ubuntu@192.168.1.10 docker swarm join-token worker
# Dann Deployment neu starten
```

### **Problem: Services starten nicht im Swarm**
```bash
# Logs pr√ºfen
docker service logs brewery-monitoring_prometheus --follow
docker service ls -q | xargs -I {} docker service ps {} --no-trunc

# Ggf. docker-stack.yml pr√ºfen
cd recording/monitoring
docker stack deploy --compose-file docker-stack.yml --with-registry-auth brewery-monitoring
```

### **Problem: Grafana Datasource zeigt keine Daten**
```bash
# Prometheus-Health pr√ºfen
curl http://192.168.1.10:9090/-/healthy
# InfluxDB erreichbar?
curl http://192.168.1.10:8086/health
# Telegraf Logs
docker service logs brewery-monitoring_telegraf --tail=50
```

---

## √úbersicht

Dieses Repository enth√§lt Scripts und Docker-Compose-Konfigurationen zur Orchestrierung der Anwendungs- und Monitoring-Services. Ziel ist eine unkomplizierte Umgebung zum Deployen, √úberwachen und Testen der Infrastruktur auf einem oder mehreren Hosts.

**Modi:**
- **Single-Node:** Docker + Portainer (einfaches Setup)
- **Multi-Node Swarm:** Automatische Metrik-Aggregation √ºber alle Nodes mit Replicas
- **Manager-HA:** Mehrere Swarm-Manager f√ºr h√∂here Verf√ºgbarkeit
- **Hotspot-Mode:** Optional WLAN-Access-Point auf einem Node

**Wichtige Bestandteile:**
- `deploy_infra.sh` ‚Äì Haupt-Deploy-Script mit Swarm-Unterst√ºtzung
- `postinstall/*.sh` ‚Äì Host-Vorbereitung (Core, Monitoring, Hotspot, Swarm)
- `monitoring/docker-stack.yml` ‚Äì Swarm-kompatible Stack-Definition
- `monitoring/docker-compose.yml` ‚Äì Standard Docker Compose (Fallback)
- `env/brewery.env` ‚Äì Umgebungsvariablen

---

## Voraussetzungen ‚úÖ

- SSH-Zugriff auf alle Ziel-Hosts
- `rsync` auf lokaler Maschine (f√ºr Dateien-Transfer)
- Bash auf allen Hosts
- Tipp: Unter macOS empfiehlt sich die Installation √ºber Docker Desktop; SSH Keys f√ºr passwordless Login konfigurieren

---

---

## Schnellstart: Lokal/Single-Node (mit Docker Compose) ‚ö°

Falls du das System lokal auf einer einzelnen Maschine (ohne remote SSH/Swarm) testen m√∂chtest:

```bash
git clone <repo-url>
cd remoteServerInfra

chmod +x ./deploy_infra.sh

# Core + Monitoring starten
docker compose -f monitoring/docker-compose.yml up -d
```

- Grafana: http://localhost:3000 (Admin / `BenFra2020!!`)
- Prometheus: http://localhost:9090
- InfluxDB: http://localhost:8086

---

## N√ºtzliche Befehle im Betrieb

```bash
# Swarm Status
docker node ls
docker service ls

# Stack neu deployen (nach Config-√Ñnderung)
cd /home/ubuntu/brewery-infra/monitoring
docker stack deploy -c docker-stack.yml brewery-monitoring

# Service-Logs folgen
docker service logs brewery-monitoring_telegraf -f

# Node-Labels f√ºr Scheduling
docker node update --label-add region=zone-a <NODE_NAME>

# Service-Replikas √§ndern
docker service scale brewery-monitoring_telegraf=5
```

---

## üìö Architektur & Monitoring Details üîß

Container-Services und deren Rollen:

- **Prometheus** (Manager-only): Scraping & Zeitreihen-DB
- **Grafana** (Manager-only): Visualisierung & Dashboards
- **InfluxDB** (Manager-only): MQTT-Daten-Speicher
- **node-exporter** (global): Hardware-Metriken von jedem Node
- **cAdvisor** (global): Container-Metriken pro Host
- **Glances** (global): System-Monitoring mit Web-UI
- **Telegraf** (2+ Replikas distributed): MQTT-Listener, Metriken-Exporter

**Netzwerk:**
- Overlay-Netzwerk `monitoring` f√ºr sichere Service-Kommunikation
- Alle Services k√∂nnen sich per Hostname `<service-name>` erreichen

**Konfigurationen:**
- `monitoring/prometheus/prometheus.yml` ‚Äì Scrape-Targets
- `monitoring/telegraf/telegraf.conf` ‚Äì MQTT & InfluxDB Config
- `monitoring/grafana/provisioning/` ‚Äì Dashboards & Datasources

### Standard-Ports

| Port  | Service        | Zugriff         |
|-------|----------------|----|
| 3000  | Grafana        | Host:3000 |
| 9090  | Prometheus     | Host:9090 |
| 8086  | InfluxDB       | Host:8086 |
| 9273  | Telegraf/Prom  | Host:9273 |
| 9100  | node-exporter  | Nur intern (Service Discovery) |
| 8085  | cAdvisor       | Host:8085 |
| 61028 | Glances        | Host:61028 |

---

## üìù Quick-Reference: H√§ufige Deploy-Befehle

```bash
# ========== MANAGER SETUP ==========
export TARGET_USER="ubuntu"
export TARGET_HOST="192.168.1.10"
export TARGET_DIR="/home/ubuntu/brewery-infra"

./deploy_infra.sh --core-only
./deploy_infra.sh --monitoring --swarm-init --swarm-advertise-addr=192.168.1.10

# ========== WORKER SETUP ==========
export TARGET_HOST="192.168.1.11"  # pro Worker √§ndern

./deploy_infra.sh --core-only
./deploy_infra.sh --monitoring --swarm-join-worker --swarm-manager-addr=192.168.1.10:2377

# ========== SWARM INSPECTION (im Manager) ==========
docker node ls                                    # Alle Nodes anzeigen
docker service ls                                # Services im Swarm
docker stack services brewery-monitoring         # Services im Stack
docker service logs brewery-monitoring_telegraf  # Service-Logs

# ========== STACK VERWALTUNG (im Manager) ==========
cd /home/ubuntu/brewery-infra/monitoring
docker stack deploy -c docker-stack.yml brewery-monitoring  # Stack neu deployen
docker service scale brewery-monitoring_telegraf=3          # Service skalieren

# ========== TOKEN-ABRUF ==========
ssh ubuntu@192.168.1.10 "docker swarm join-token worker -q"   # Worker-Token
ssh ubuntu@192.168.1.10 "docker swarm join-token manager -q"  # Manager-Token
```

---

## Mitwirken (Contributing) ü§ù

Pull Requests sind willkommen. Bitte folge dem bestehenden Stil und dokumentiere gr√∂√üere √Ñnderungen im Changelog (oder in einem PR-Description-Template).

---

## Lizenz & Kontakt

Standardm√§√üig ist keine Lizenz hinterlegt ‚Äî f√ºge bei Bedarf eine `LICENSE`-Datei hinzu (z.B. MIT).

Bei Fragen: √∂ffne ein Issue oder kontaktiere die Maintainer √ºber das Repository.

---

Viel Erfolg beim Deployen und Monitoring! üöÄ
